{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final.ipynb","provenance":[{"file_id":"1ObAYvVKQjMG5nd2wIno7j2y_X91E9IrX","timestamp":1647457248831}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jF8ZoVrwt0n0"},"source":["# SimCLR\n","The goal of this report is to show our effort in reproducing the paper \"A Simple Framework for Contrastive Learning of Visual Representation\". [Link to paper](https://arxiv.org/pdf/2002.05709.pdf) We reimplement SIMCLR using pytorch on the basis of official tensorflow version. Moreover, as the requirement of the course, we reproduce the result in table 8 on cifar 10 dataset and get a nice visualization effect on trained image vectors. Morever, we also extends our work to a new dataset RPLAN, and also achieves good visualizaton result. In general, our work can be divided into following parts:\n","\n","- Reimplement the paper using pytorch on jupyter notebook.\n","\n","- Reproduce the result of table 8 in the paper using different training strategy, including finetuning and linear evaluation, by using pretrained RESTNET(1X) and RESNET(4X) model.\n","\n","- Extend to apply SIMCLR on RPLAN dataset. The work includes applying transform on RPLAN images(so that they can fit in the model) and pretrain on these images.\n","\n","- Visualize the trained image vectors on CIFAR10 and RPLAN dataset by using PCA and SNE, and analysis the pretraining performance of the model.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lt6WMxjCvN3o"},"source":["## First we need to setup the repository for the following work. During our reproduction work, we adapt the code in this [repository](https://github.com/Spijkervet/SimCLR) and made a number of adjustments on it. Besides, we also need to install required environment packages so that our code can run correctly."]},{"cell_type":"code","metadata":{"id":"53JMIYtat8tT"},"source":["!git clone https://github.com/harrychen23235/SimCLR.git\n","%cd SimCLR\n","!mkdir -p logs && cd logs && cd ../\n","!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n","!pip install  pyyaml --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tAQpjiuJy61N"},"source":["# Part 2:\n","#### This part mainly focuses on reproducing the table 8 result on CIFAR10 in the paper. We use the official pretrained checkpoint to pre-load the RESNET model before finetuning. To make our model fit in downstream classfication task, we add a logistic regerssion layer at the end of RESNET model. We train on the model using two different training strategies, finetuning and linear evaluation. Finetuning is just like normal training process, the gradient passes through all the model and all parameters get updated after one backward. For linear evaluation, the parameter of RESNET model is frozen while training, and only the parameter of logistic regression layer gets updated. Two strategies share almost the same code, the only difference is mainly in training and testing process. Two different versions of RESNET models are used, inluding RESNET50(1X) and RESNET50(4X), and we train the model for 500 epoches and compare the test accuracy with the result in the paper.The result will be shown in later part of the report.\n"]},{"cell_type":"markdown","metadata":{"id":"7XPCSCKSrPCA"},"source":["#### Install PyTorch/XLA"]},{"cell_type":"code","metadata":{"id":"dO7TYZPXrPCA"},"source":["import os\n","import torch\n","import numpy as np\n","import torchvision\n","import argparse\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","apex = False\n","try:\n","    from apex import amp\n","    apex = True\n","except ImportError:\n","    print(\n","        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n","    )\n","\n","from model import save_model, load_optimizer\n","from simclr import SimCLR\n","from simclr.modules import get_resnet, NT_Xent\n","from simclr.modules.transformations import TransformsSimCLR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Import package in our repository and Pytorch."],"metadata":{"id":"OufUoDAzVltw"}},{"cell_type":"code","metadata":{"id":"kFyS9RvpuCuC"},"source":["import torch\n","import torchvision\n","import numpy as np\n","import argparse\n","from simclr.modules import LogisticRegression\n","from simclr.modules.resnet_wider import resnet50x4,resnet50x1"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmevIyLsqQ4C","executionInfo":{"status":"ok","timestamp":1649345648226,"user_tz":-120,"elapsed":12943,"user":{"displayName":"Chen Congwen","userId":"01522578530684319350"}},"outputId":"f0177f37-cb57-4546-fd25-162bdb684c43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### This function is the Training Function used in Linear evaluation scenario. Obviously, only logistic regression layer participates in the training."],"metadata":{"id":"kgJybqRRwYLo"}},{"cell_type":"code","metadata":{"id":"pZRtPBCLvgqz"},"source":["def train_linear_evaluation(args, loader, simclr_model, model, criterion, optimizer):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    for step, (x, y) in enumerate(loader):\n","        optimizer.zero_grad()\n","\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output = model(x)\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_epoch += loss.item()\n","        # if step % 100 == 0:\n","        #     print(\n","        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n","        #     )\n","\n","    return loss_epoch, accuracy_epoch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### This function is the Training Function used in finetuning scenario. Both logistic layer and RESNET model participate in training process."],"metadata":{"id":"8iPtdDbtwhHO"}},{"cell_type":"code","source":["def train_finetune(args, loader, simclr_model, model, criterion,optimizer_simclr, optimizer_model):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    for step, (x, y) in enumerate(loader):\n","        optimizer_simclr.zero_grad()\n","        optimizer_model.zero_grad()\n","\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output_first = simclr_model(x)\n","        output = model(output_first)\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss.backward()\n","\n","        optimizer_simclr.step()\n","        optimizer_model.step()\n","        loss_epoch += loss.item()\n","        if step % 10 == 0:\n","             print(\n","                 f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n","             )\n","\n","    return loss_epoch, accuracy_epoch"],"metadata":{"id":"wWe7d_wvostO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test Function used in linear evaluation scenario. The principle is the same as training function."],"metadata":{"id":"aF4wESprwp8M"}},{"cell_type":"code","metadata":{"id":"skBYAPb2uKB5"},"source":["def test_linear_evaluation(args, loader, simclr_model, model, criterion, optimizer):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    model.eval()\n","    for step, (x, y) in enumerate(loader):\n","        model.zero_grad()\n","\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output = model(x)\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss_epoch += loss.item()\n","\n","    return loss_epoch, accuracy_epoch\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test Function used in finetuning scenario. The principle is the same as training function."],"metadata":{"id":"GuAlNV8Kwuv4"}},{"cell_type":"code","source":["def test_finetune(args, loader, simclr_model, model, criterion):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    model.eval()\n","    simclr_model.eval()\n","    for step, (x, y) in enumerate(loader):\n","        model.zero_grad()\n","        simclr_model.zero_grad()\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output_first = simclr_model(x)\n","        output = model(output_first)\n","\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss_epoch += loss.item()\n","\n","    return loss_epoch, accuracy_epoch"],"metadata":{"id":"e0RHjOfqo0Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJk4-nc-vkF0"},"source":["from pprint import pprint\n","from utils import yaml_config_hook\n","\n","parser = argparse.ArgumentParser(description=\"SimCLR\")\n","config = yaml_config_hook(\"./config/config.yaml\")\n","for k, v in config.items():\n","    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n","\n","args = parser.parse_args([])\n","args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### We set the batch size as 64 for ResNet1X model and 32 for ResNet4X model. These are the maximum size we can use because if we increase it, OOM error will occur. We run our codes in CIFAR10 dataset during reproduction work but our code can also be applied on other image classication dataset, inlcluding STL10."],"metadata":{"id":"f5cgOJ9eXEVn"}},{"cell_type":"code","metadata":{"id":"_7cSwhu55KJc"},"source":["args.batch_size = 32\n","args.dataset = \"CIFAR10\" # You can also set it as \"STL10\"\n","args.epoch_num = 100\n","args.logistic_epochs = 500\n","args.logistic_batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWRuVrZZ5Vm1"},"source":["#### In this part we load dataset into train/test dataloaders. Compared with pretraining process, we don't need to apply any transform while on training dataset."]},{"cell_type":"code","metadata":{"id":"iPGuFjLW5PF9"},"source":["if args.dataset == \"STL10\":\n","    train_dataset = torchvision.datasets.STL10(\n","        args.dataset_dir,\n","        split=\"train\",\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","    test_dataset = torchvision.datasets.STL10(\n","        args.dataset_dir,\n","        split=\"test\",\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","elif args.dataset == \"CIFAR10\":\n","    train_dataset = torchvision.datasets.CIFAR10(\n","        args.dataset_dir,\n","        train=True,\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","    test_dataset = torchvision.datasets.CIFAR10(\n","        args.dataset_dir,\n","        train=False,\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","else:\n","    raise NotImplementedError\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=args.logistic_batch_size,\n","    shuffle=True,\n","    drop_last=True,\n","    num_workers=args.workers,\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=args.logistic_batch_size,\n","    shuffle=False,\n","    drop_last=True,\n","    num_workers=args.workers,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TmwXqVBH5ZX6"},"source":["#### Load ResNet encoder / SimCLR and load model weights. For the pretrained checkpoint, we use [this repo](https://github.com/tonylins/simclr-converter) to convert official checkpoint to pytorch checkpoint. As shown in the code, two different versions of ResNet are used."]},{"cell_type":"code","metadata":{"id":"RTVnvx2a5QnX"},"source":["#encoder = resnet50x4()\n","encoder = resnet50x1() \n","n_features = encoder.fc.out_features \n","simclr_model = encoder\n","#encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/simclr-converter/resnet50-4x.pth\", map_location=args.device.type)['state_dict'])\n","encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/simclr-converter/resnet50-1x.pth\", map_location=args.device.type)['state_dict'])\n","simclr_model = simclr_model.to(args.device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### We add a logistic regression layer at the end of ResNet model to fit the model in classfication task."],"metadata":{"id":"2g09xs_Obpo5"}},{"cell_type":"code","metadata":{"id":"HZoABGRr5Q8_"},"source":["n_classes = 10 \n","model = LogisticRegression(n_features, n_classes)\n","model = model.to(args.device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### We use cross entropy as the criterion to get the image classification loss. For the optimizer, we use SGD, which is also used in the paper. We also try to use Adam, and find that there is almost no performance difference compared with SGD."],"metadata":{"id":"kPp5xN-Tb9BO"}},{"cell_type":"code","metadata":{"id":"T694n_HQ5Tad"},"source":["#optimizer_model = torch.optim.Adam(model.parameters(), lr=3e-4)\n","optimizer_model = torch.optim.SGD(model.parameters(), lr=0.0001, weight_decay=1e-6,momentum = 0.9)\n","optimizer_simclr = torch.optim.SGD(simclr_model.parameters(), lr=0.0001, weight_decay=1e-6,momentum = 0.9)\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLgDCu1uTLQ5"},"source":["#### Helper functions to map all input data $X$ to their latent representations $h$ that are used in linear evaluation (they only have to be computed once)."]},{"cell_type":"code","metadata":{"id":"6B6li5NVSWR3"},"source":["def inference(loader, simclr_model, device):\n","    feature_vector = []\n","    labels_vector = []\n","    for step, (x, y) in enumerate(loader):\n","        x = x.to(device)\n","\n","        # get encoding\n","        with torch.no_grad():\n","            h = simclr_model(x)\n","\n","        h = h.detach()\n","\n","        feature_vector.extend(h.cpu().detach().numpy())\n","        labels_vector.extend(y.numpy())\n","\n","        if step % 20 == 0:\n","            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n","\n","    feature_vector = np.array(feature_vector)\n","    labels_vector = np.array(labels_vector)\n","    print(\"Features shape {}\".format(feature_vector.shape))\n","    return feature_vector, labels_vector\n","\n","\n","def get_features(context_model, train_loader, test_loader, device):\n","    train_X, train_y = inference(train_loader, context_model, device)\n","    test_X, test_y = inference(test_loader, context_model, device)\n","    return train_X, train_y, test_X, test_y\n","\n","\n","def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n","    train = torch.utils.data.TensorDataset(\n","        torch.from_numpy(X_train), torch.from_numpy(y_train)\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train, batch_size=batch_size, shuffle=False\n","    )\n","\n","    test = torch.utils.data.TensorDataset(\n","        torch.from_numpy(X_test), torch.from_numpy(y_test)\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test, batch_size=batch_size, shuffle=False\n","    )\n","    return train_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPeoK6ZkS4MB"},"source":["\n","\n","print(\"### Creating features from pre-trained context model ###\")\n","(train_X, train_y, test_X, test_y) = get_features(\n","    encoder, train_loader, test_loader, args.device\n",")\n","\n","arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n","    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training&Testing procedure in linear evaluation scneario"],"metadata":{"id":"QTqlQ4EIxLQo"}},{"cell_type":"code","metadata":{"id":"vLaebM9Qvztx"},"source":["for epoch in range(args.logistic_epochs):\n","    loss_epoch, accuracy_epoch = train_linear_evaluation(args, arr_train_loader, simclr_model, model, criterion, optimizer_model)\n","    \n","    if epoch % 10 == 0:\n","      print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n","\n","\n","# final testing\n","loss_epoch, accuracy_epoch = test_linear_evaluation(\n","    args, arr_test_loader, simclr_model, model, criterion, optimizer_model\n",")\n","print(\n","    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training&Testing procedure in finetuning scneario"],"metadata":{"id":"lU0_iTsjxbFM"}},{"cell_type":"code","source":["for epoch in range(args.logistic_epochs):\n","    loss_epoch, accuracy_epoch = train_finetune(args, train_loader, simclr_model, model, criterion, optimizer_simclr, optimizer_model)\n","    print(accuracy_epoch)\n","    if epoch % 10 == 0:\n","      print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n","\n","\n","loss_epoch, accuracy_epoch = test_finetune(\n","    args, test_loader, simclr_model, model, criterion\n",")\n","print(\n","    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",")"],"metadata":{"id":"mITVveGVpbGC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Analysis on loss curve"],"metadata":{"id":"PD47wlulqweo"}},{"cell_type":"markdown","source":["### Linear Evaluation"],"metadata":{"id":"3GNBxPZvsI17"}},{"cell_type":"markdown","source":["#### We use weight & biase to get the loss curve of training process. As shown in the following graph. During linear evaluation, the model quickly converges and the loss almost reaches 0 in around 200 epoches. We also compare the convergence speed between ResNet1X and ResNet4X. The result shows that a larger pretraining model won't make the logistic regerssion layer converge faster.\n","<img src=\"https://s1.ax1x.com/2022/04/08/LpA8N6.png\" alt=\"i1\" style=\"zoom:100%;\" /><img src=\"https://cdn.discordapp.com/attachments/884910103428476989/961713567076352130/WB_Chart_4_7_2022_9_41_15_PM.png\" alt=\"i2\" style=\"zoom:20%;\" /><img src=\"https://cdn.discordapp.com/attachments/884910103428476989/961717185229779024/WB_Chart_4_7_2022_10_00_22_PM.png\" alt=\"i2\" style=\"zoom:20%;\" /><img src=\"https://cdn.discordapp.com/attachments/884910103428476989/961717185468850206/WB_Chart_4_7_2022_10_00_28_PM.png\" alt=\"i2\" style=\"zoom:0%;\" />\n"],"metadata":{"id":"JYKSyV2tf2Mf"}},{"cell_type":"markdown","source":["### finetune"],"metadata":{"id":"g1TyZUo7p-Xs"}},{"cell_type":"markdown","source":["We also plot the learning curve of finetuning training phase and compare it with the learning curve while the model learns from scratch."],"metadata":{"id":"DD-PUbqhsWwU"}},{"cell_type":"markdown","source":["## Result comparison"],"metadata":{"id":"gChmBu7Tsz_B"}},{"cell_type":"markdown","source":["In this section, we compare the performance of different training strategies and the same strategy with the performance in the paper. All the results are shown in the following table. We fail to run ResNet4X finetune because lack of computational resource. Our ResNet1X finetuning has almost the same performance \n","compared with original paper. However, after trying different training settings , our linear evaluation still can not achieve the same performance as the paper. After reading the paper and comparing our code with the official code, I think it might result from the small batch size we use. The author shows that a larger batch size over 512 can significantly increase the performance. But because of lack of memory resource, that is not applicable for us.\n","\n","| Training Setup              | Note                          | Accuracy           |\n","| --------------------------- | ----------------------------- | ------------------ |\n","| ResNet1X finetune           | loading pretrained checkpoint | 0.955 |\n","| ResNet1X finetune           | learn from scratch            | 0.823|\n","| ResNet1X finetune           | in the original paper         | 0.977              |\n","| ResNet1X linear evaluation  | our implementation            | 0.852  |\n","| RestNet1X linear evaluation | in the original paper         | 0.906               |\n","| ResNet4X linear evaluation  | our implementation            | 0.897 |\n","| ResNet4X linear evaluation  | in the original paper         | 0.953              |"],"metadata":{"id":"jMu4hN_ks7ZB"}}]}