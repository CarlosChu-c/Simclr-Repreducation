{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF8ZoVrwt0n0"
   },
   "source": [
    "# Visualization on CIFAR10 Dataset\n",
    "In this notebook, we will try to project the CIFAR10 dataset by SimCLR to evaluate the performance of our model.\n",
    "\n",
    "The main work can be divided into 2 parts:\n",
    "1. Use the pre-trained SimCLR model to project the CIFAR10 dataset into embedding space.\n",
    "2. Use tensorboard to visualize the embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt6WMxjCvN3o"
   },
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12179,
     "status": "ok",
     "timestamp": 1648494165688,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "53JMIYtat8tT",
    "outputId": "3d385fc8-7e1b-4476-94df-07ae8047068a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p logs && cd logs && wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar && cd ../\n",
    "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "!pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ3jq3cWynLf"
   },
   "source": [
    "# Part 1:\n",
    "## Load SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jhAv3hv8IHn"
   },
   "outputs": [],
   "source": [
    "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
    "use_tpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwW10d2O7pn8"
   },
   "source": [
    "#### Install PyTorch/XLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj84aiC27oxS"
   },
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "  VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "  !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10071,
     "status": "ok",
     "timestamp": 1648494191901,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "oNDRcPbbymlX",
    "outputId": "a53087c4-b989-493b-d61f-4e5e4d526230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "if use_tpu:\n",
    "  # imports the torch_xla package for TPU support\n",
    "  import torch_xla\n",
    "  import torch_xla.core.xla_model as xm\n",
    "  dev = xm.xla_device()\n",
    "  print(dev)\n",
    "  \n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "from model import save_model, load_optimizer\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYbV0fa_y03Z"
   },
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1klUf-IuyxdL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import argparse\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1648494202523,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "O86__UhA0Lvr",
    "outputId": "960c684f-a747-45d2-8e99-e7d001a92e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'dataset_dir': './datasets',\n",
      " 'device': device(type='cuda'),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 100,\n",
      " 'gpus': 1,\n",
      " 'image_size': 224,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'save',\n",
      " 'nodes': 1,\n",
      " 'nr': 0,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 8}\n"
     ]
    }
   ],
   "source": [
    "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "args.batch_size = 128\n",
    "args.resnet = \"resnet18\"\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJfeOM9PzNoF"
   },
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8092,
     "status": "ok",
     "timestamp": 1648494215320,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "YGcskdBsytbj",
    "outputId": "240b21a0-cd6f-46eb-b005-edfab3d3c57f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"unlabeled\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.nodes > 1:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBlXZwvjzPmp"
   },
   "source": [
    "### Project the TESTSET to the embedding space.\n",
    "Here,we project the test set to the embedding space by SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xERq_yHSzJRX"
   },
   "outputs": [],
   "source": [
    "# initialize ResNet\n",
    "encoder = get_resnet(args.resnet, pretrained=False)\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# initialize model\n",
    "model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "if args.reload:\n",
    "    model_fp = os.path.join(\n",
    "        args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "model = model.to(args.device)\n",
    "\n",
    "# optimizer / loss\n",
    "optimizer, scheduler = load_optimizer(args, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1648494230431,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "0i6uHHzl3ac_",
    "outputId": "58ca02ea-8f47-4a08-d2ae-886136760caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZRtPBCLvgqz"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skBYAPb2uKB5"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJk4-nc-vkF0"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if use_tpu:\n",
    "  args.device = dev\n",
    "else:\n",
    "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7cSwhu55KJc"
   },
   "outputs": [],
   "source": [
    "args.batch_size = 64\n",
    "args.logistic_batch_size = 64\n",
    "args.dataset = \"CIFAR10\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.resnet = \"resnet50\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.model_path = \"logs\"\n",
    "args.epoch_num = 100\n",
    "args.logistic_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTgCE-mZ7ygx"
   },
   "source": [
    "### Download a pre-trained model for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2414,
     "status": "ok",
     "timestamp": 1648494265349,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "WMuPgP3h7vfi",
    "outputId": "34bd0f3c-94dc-401d-e6cd-1c84f4806896",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWRuVrZZ5Vm1"
   },
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2717,
     "status": "ok",
     "timestamp": 1648494269720,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "iPGuFjLW5PF9",
    "outputId": "7e8724cd-e295-4072-9acb-6a13236e4623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"train\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"test\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmwXqVBH5ZX6"
   },
   "source": [
    "### Load ResNet encoder / SimCLR and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTVnvx2a5QnX"
   },
   "outputs": [],
   "source": [
    "encoder = resnet50x1() # don't load a pre-trained model from PyTorch repo\n",
    "n_features = encoder.fc.out_features \n",
    "# load pre-trained model from checkpoint\n",
    "simclr_model = encoder\n",
    "encoder.load_state_dict(torch.load(\"/content/drive/MyDrive/converter_checkpoint/resnet50-1x.pth\", map_location=args.device.type)['state_dict'])\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZoABGRr5Q8_"
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = 10 # stl-10 / cifar-10\n",
    "model = LogisticRegression(n_features, n_classes)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T694n_HQ5Tad"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLgDCu1uTLQ5"
   },
   "source": [
    "### Helper functions to map all input data $X$ to their latent representations $h$ that are used in linear evaluation (they only have to be computed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6B6li5NVSWR3"
   },
   "outputs": [],
   "source": [
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h = simclr_model(x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190802,
     "status": "ok",
     "timestamp": 1648494469750,
     "user": {
      "displayName": "MT AB",
      "userId": "12376781480150994694"
     },
     "user_tz": -120
    },
    "id": "sPeoK6ZkS4MB",
    "outputId": "643409e6-b44e-4e8a-c57f-bd831ed6cea5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Visualization\n",
    "In this part, we will visualize the embedding space of the train set. We refer to the blog How to visualize image feature vectors. And we will use tensorboard visualize the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL1QcQdvA3JR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import csv\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYu_tCdGAvkF"
   },
   "outputs": [],
   "source": [
    "image_number = 4000\n",
    "trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([32, 32])\n",
    "  ]\n",
    ")\n",
    "DatasetPIL = []\n",
    "for (images,_) in test_loader:\n",
    "  for image in images:\n",
    "    DatasetPIL.append(trans(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3ZQ1t6qAxFN"
   },
   "outputs": [],
   "source": [
    "image_width, image_height = images[0].size\n",
    "one_square_size = int(np.ceil(np.sqrt(len(images))))\n",
    "master_width = (image_width * one_square_size) \n",
    "master_height = image_height * one_square_size\n",
    "spriteimage = Image.new(\n",
    "    mode='RGBA',\n",
    "    size=(master_width, master_height),\n",
    "    color=(0,0,0,0))  # fully transparent\n",
    "for count, image in enumerate(images):\n",
    "    div, mod = divmod(count,one_square_size)\n",
    "    h_loc = image_width*div\n",
    "    w_loc = image_width*mod    \n",
    "    spriteimage.paste(image,(w_loc,h_loc))\n",
    "spriteimage.convert(\"RGB\").save('vis/sprite.jpg', transparency=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icXRUdRDBCmb"
   },
   "outputs": [],
   "source": [
    "vecs = [vec for vec in test_X[:image_number]]\n",
    "with open('feature_vecs.tsv', 'w+') as fw:\n",
    "    csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "    csv_writer.writerows(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "label = ['airplane',\n",
    " 'automobile',\n",
    " 'bird',\n",
    " 'cat',\n",
    " 'deer',\n",
    " 'dog',\n",
    " 'frog',\n",
    " 'horse',\n",
    " 'ship',\n",
    " 'truck']\n",
    "existing_images_df = pd.DataFrame([(label[id],id) for id in test_y[:image_number]],\n",
    "                                  columns=['cat_id', 'pid'])"
   ],
   "metadata": {
    "id": "9CdWDMzWjqU4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metadata = existing_images_df[['cat_id', 'pid']].to_csv('vis/metadata.tsv', sep='\\t', index=False)"
   ],
   "metadata": {
    "id": "vDsaDIz9jDSR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Visiualization.ipynb",
   "provenance": [
    {
     "file_id": "1ObAYvVKQjMG5nd2wIno7j2y_X91E9IrX",
     "timestamp": 1647457248831
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}